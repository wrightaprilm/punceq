
fromTrace = FALSE

### This director needs three subdirectories (folders):
#     scripts/ (additional RevBayes routines that will be used)
#     data/ (holds data matrices & taxonomic information)
#     output/ (where trees & logs will be sent)
source("scripts/standard_routines/Milgram_Default_Settings.Rev");

###############################################################################
#                  Get basic information about the clade                   #
# This is (these are) the nexus file(s) that you are using for this analysis  #
#     Make sure that filenames & directories are correct!!!
###############################################################################
analysis_name <- "Strophomenida";
timeline_precision <- 0.05;
#taxa <- readTaxonData("data/Strophomenida_fossil_intervals.tsv");
taxa <- readTaxonData("data/Strophomenida_fossil_intervals_w_outgroup.tsv");
otus <- n_taxa <- taxa.size();
n_branches <- (2 * n_taxa) - 2;

max_max_age <- taxa[1].getMaxAge();
for (i in 2:otus) if (max_max_age < taxa[i].getMaxAge())   max_max_age <- taxa[i].getMaxAge();
if (round(max_max_age)<max_max_age) {
  max_max_age <- 1+round(max_max_age);
  } else {
  max_max_age <- round(max_max_age);
  }
origin_time ~ dnUnif(max_max_age,max_max_age*2);  # Specify a uniform prior on the origin #

filenames <- v("data/Strophomenida_Matrix_2_States_w_outgroup.nex","data/Strophomenida_Matrix_3_States_w_outgroup.nex","data/Strophomenida_Matrix_4_States_w_outgroup.nex");
n_data_subsets <- filenames.size();
for (nd in 1:n_data_subsets) {
  morpho[nd] <- readDiscreteCharacterData(filenames[nd]);
#  print(morpho[nd])
  partition_chars[nd] <- morpho[nd].nchar();
  }
partition_states <- v(2,3,4);
partition_ordering <- v("unordered","unordered","unordered");
coding_bias <- v("variable","variable","variable");	## prepare for ascertainment bias in binary characters; 'all': invariant & autapomorphies present; 'variable': all vary & autapomorphies present; 'informative': all vary & no autapomorphies.

###############################################################################
#                  Setup parameters for the analyses                   #
#     Again, make sure that filenames & directories are correct!!!
###############################################################################
clock_model <- "strict";		# enter "strict" for strict clock, "uncorrelated" for relaxed clock with lognormal; "autocorrelated" for autocorrelated with lognormal shifts
among_char_var <- "lognormal";	# enter "gamma" or "lognormal"continuous <- TRUE;
punctuated <- FALSE;
if (punctuated) {
  pr_pe <- 1;   # prob. of speciation event 'initiating' cladistic branch
  } else {
  pr_pe <- 0;
  }

outgroup=clade("Sowerbyites");
ingroup=clade("Strophomena","Keilamena","Tetraphalerella","Actinomena","Holtedahlina","Longvillia","Leigerina","Pseudostrophomena","Furcitella","Bekkerina","Bellimurina","Biparetis","Dactylogonia","Geniculina","Katastrophomena","Chunanomena","Luhaia","Molongcola","Murinella","Oepikina","Quondongia","Crassoseptaria","Haljalanites","Colaptomena","Kjerulfina","Rafinesquina","Megamyonia","Rhipidomena","Kjaerina","Septomena","Leptaena","Kiaeromena","Bekkeromena","Glyptomena","Paromalomena","Platymena","Resupinsculpta");
timeline <- v(1.25,5.45,8.8,14.25,17.65,25.45,27.3,29.55,33.15,38.45,42.9);
seed_origination <- v(0.334,0.2059,0.2616,0.6103,0.6431,0.7389,0.1055,0.7797,0.3966,0.3999,0.2567,0.2468);
seed_sampling <- v(0.4763,0.5701,0.3794,0.6824,0.877,0.5102,0.5328,0.6018,0.5829,0.6313,0.6389,0.7845);
seed_sampling_lb <- v(0.0956,0.1102,0.0597,0.1631,0.3483,0.2427,0.0642,0.1815,0.1155,0.1954,0.1765,0.2979);
seed_sampling_ub <- v(0.2647,0.3252,0.1608,0.5068,0.9199,0.4737,0.1851,0.3943,0.2732,0.4245,0.3631,0.8233);
nbins <- seed_sampling.size();
rho <- 0.3789;

############################################################################
# Set up appropriate parameters for speciation, extinction & sampling.     #
#      We also set up the tree search here.                                #
#                                                                          #
# NOTE: This will sometimes freeze; if it does, then edit the script so    #
#      origination & extinction are set to 1.0. This usually works!        #
############################################################################
moves = VectorMoves();
source("scripts/FBD_scripts/Milgram_Skyline_N_Interval.Rev");

############################################################################
# Set up appropriate Q-matrices for the partitions
#   as well as the among-character and among-branch
#   rate variation models
#  (Again, make sure that the directory is OK)
############################################################################

if (ttl_rate_partitions==1)  {
  if (clock_model=="strict")  {
    source("scripts/branch_rate_scripts/Milgram_Strict_Clock_Branch_Rates.Rev");
    } else if (clock_model=="uncorrelated" || clock_model=="lognormal")  {
    source("scripts/branch_rate_scripts/Milgram_Uncorrelated_Lognormal_Relaxed_Clock_Branch_Rates.Rev");
    } else if (clock_model=="big_bang" || clock_model=="early_burst")  {
    source("scripts/branch_rate_scripts/Milgram_Early_Burst_Branch_Rates.Rev");
    # rate variation on branches comes from decay over time only
    } else if (clock_model=="autocorrelated")  {
    source("scripts/branch_rate_scripts/Milgram_Autocorrelated_Lognormal_Relaxed_Clock_Branch_Rates.Rev");
    }
  }  else if (ttl_rate_partitions > 1)  {
  if (clock_model=="strict")  {
    source("scripts/branch_rate_scripts/Milgram_Strict_Clock_Branch_Rates_Partitioned.Rev");
    } else if (clock_model=="uncorrelated" || clock_model=="log_normal")  {
    source("scripts/branch_rate_scripts/Milgram_Lognormal_Relaxed_Clock_Branch_Rates_Partitioned.Rev");
    }
  }

# Setup gamma or lognormal variation shared by characters in each partition.
for (pt_no in 1:ttl_rate_partitions)  {
# all characters in this partition have the same gamma or lognormal regardless of states
  if (among_char_var=="uniform" || among_char_var=="invariant")  {
    alpha[pt_no]=1;
    }  else {
    alpha[pt_no] ~ dnExponential( 1.0 );
    moves.append(mvScale(alpha[pt_no], lambda=0.01, tune=true, weight=5));
    moves.append(mvScale(alpha[pt_no], lambda=0.10, tune=true, weight=3));
    moves.append(mvScale(alpha[pt_no], lambda=1.00, tune=true, weight=1));
    }
  # set up rate distribution to describe variation among characters
  if (among_char_var=="gamma")  {
    partition_char_rate_var[pt_no] := fnDiscretizeGamma( alpha[pt_no], alpha[pt_no], 4 );
    # NOTE: this sets the shape and scale parameters equal so that the mean is always 1.0.
    } else if (among_char_var=="lognormal")  {
    partition_char_rate_var[pt_no] := fnDiscretizeDistribution(dnLognormal(mean=0,sd=alpha[pt_no]), 4);
    # NOTE: This varies only log-variance; the geometric mean (= median) is always 1.0.
    } else if (among_char_var=="uniform" || among_char_var=="invariant")  {
    partition_char_rate_var[pt_no] <- fnDiscretizeDistribution(dnLognormal(mean=0,sd=0), 1);
    }# end case of lognormal
  } # end rate distribution for this character partition

# for each dataset, link the appropriate data matrix, Q-matrix, among-character rate variation model, and among-branch rate variation model
for (nds in 1:n_data_subsets)  {
  golem[nds] <- readDiscreteCharacterData(filenames[nds]);

  # set up transition matrices

    Q[nds]:=fnJC(partition_states[nds]);

  # set up appropriate rates
  if (ttl_rate_partitions>1)  {
    # all characters in this partition have the same gamma or lognormal regardless of states
    pt_no <- 1;
    while(rate_partitions[nds]!=rate_partition_labels[pt_no]) ++pt_no;
    char_rate_var[nds] := partition_char_rate_var[pt_no];
    if (punctuated)  {
#      for (bn in 1:n_branches) ind_branch_rates[nds][bn]:=abs(abs(exp_branchings[pt_no])*abs(branch_rates[pt_no]));
      ind_branch_rates[nds]:=abs(abs(exp_branchings[pt_no])*abs(branch_rates[pt_no]));  # set deterministic node that we can use regardless of the model of per-branch variation
      } else {
      ind_branch_rates[nds]:=branch_rates[pt_no];  # set deterministic node that we can use regardless of the model of per-branch variation
      }
    } else  {
    # all characters in this partition have the same gamma or lognormal regardless of states
    char_rate_var[nds] := partition_char_rate_var[1];
    if (punctuated)  {
#      for (bn in 1:n_branches) ind_branch_rates[nds][bn]:=abs(abs(exp_branchings[bn])*abs(branch_rates[bn]));
      ind_branch_rates[nds]:=abs(abs(exp_branchings)*abs(branch_rates));
      } else {
      ind_branch_rates[nds]:=branch_rates;
      }
    }  # end case where all state partitions in a rate partition have the same gamma/lognormal & alpha

  # attach appropriate rate variation for branches given character class.
#  phyMorpho[nds] ~ dnPhyloCTMC(tree=tau,Q=Q[nds],nSites=partition_chars[nds],siteRates=char_rate_var[nds],branchRates=ind_branch_rates[nds],type="Standard",coding=coding_bias[nds]);
#  phyMorpho[nds] ~ dnPhyloCTMC(tree=fbd_tree,Q=Q_morpho,siteRates=rates_morpho, branchRates=branch_rates, type="Standard", coding="variable", rootFrequencies = root_state)
  phyMorpho[nds] ~ dnPhyloCTMC(tree=fbd_tree,Q=Q[nds],siteRates=char_rate_var[nds],branchRates=ind_branch_rates[nds],type="Standard",coding=coding_bias[nds]);
  phyMorpho[nds].clamp(golem[nds]);
  }

